{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting with graphframe and pyspark\n",
    "\n",
    "I tend to follow the User guide for Graphframe and that is posted on Databricks https://docs.databricks.com/spark/latest/graph-analysis/graphframes/user-guide-python.html. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.GHnet import *\n",
    "from src.parse_edges import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, read the fork edges and the contribution edges from the text file `fork_edges.txt` and `contrib_edges.txt`. For each line in the two files, the edges will be in the form of a tuple `(u,r)` or `(r,u)`. Here `r` and `u` specifies the repositories ID and user ID on GitHub. For more information about the storage formats of `fork_edges.txt` and `contrib_edges.txt`. and how edges are collected (and how the network is formed), please consult the meta file `meta.md`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we read in the contribution edges and fork edges, we will build the Biparitite Graph using Graphframe. Now, we will convert the text file that contains the edges into two parquet file `vertices.parquet` and `edges.parquet`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_to_pq(contrib_edge_file='data/contrib_edges.txt',\n",
    "          fork_edge_file='data/fork_edges.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, using these two parquet file, we will construct a graphframe object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = GHnet(vertices_pq='data/vertices.parquet',\n",
    "            edges_pq='data/edges.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary EDA on the Graph\n",
    "After we create a graphframe object, we can now do some preliminary EDA on the graph. One straightfoward thing we can check is the in and out degree distribution of the users and repos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-3579a35bf5a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdemo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdegree_dist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeg_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'f'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/s651/651_Project/src/GHnet.py\u001b[0m in \u001b[0;36mdegree_dist\u001b[0;34m(self, deg_type, plot, id)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;31m# of out Degrees of repos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mplot\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0msamp_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mdegree_quantile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdegree_dtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m                     .approxQuantile(col=colName,\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "demo.degree_dist(deg_type='f', plot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Page Rank of GitHub's repository and users\n",
    "Top ten influential repository?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Spectrum\n",
    "Since we don't have the direct collaboration information between users (which requires push access to specific repo), we are only able to collect the contributors of specific repos and users who fork the repos. Thus the contribution-fork edge network is bipartite.\n",
    "\n",
    "Let $A$  be the Adjacency matrix of GitHub's contribution-fork network and assume there are $m$ repos and $n$ users. $A_{ur}$ be the adjacency matrix that represents contribution edges, and $A_{ru}$ be the adjacency matrix that represents the fork edges. Then $A$ can be written in block matrix form $$A = \\begin{pmatrix} 0_n & A_{ur}\\\\ A_{ru}& 0_m\\end{pmatrix}$$. Thus the matrix $A$ is singular, thus having 0 eigenvalue. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Community Detection\n",
    "Implement community detection algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (If Time allows) Matrix completion problem\n",
    "We now observe a bipartite contribution-fork network. But we know that users on GitHub collaborate with each other (or they can follow someone they look up to) and repos depends on other repos as well (unless developers enjoy torturing themselves or tired of being tortured by shitty packages they use on a daily basis). We can think of this as a matrix completion problem, where we want to fill in the unobserved entries in our population adjacency matrix. Suppose we have a small sample of collaboration/follower and repository dependency information, can we use that to complete our population graph?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
